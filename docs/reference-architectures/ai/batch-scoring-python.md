---
title: Pontuação em lote de modelos Python no Azure
description: Compile uma solução escalonável para modelos de pontuação em lote com agendamento em paralelo usando o Serviço Azure Machine Learning.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: b7607984bcf2c4bd046421aeb6e9d52dd8e7c18e
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887736"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="afd22-103">Lote de pontuação de modelos de aprendizado de máquina do Python no Azure</span><span class="sxs-lookup"><span data-stu-id="afd22-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="afd22-104">Esta arquitetura de referência mostra como compilar uma solução escalonável para pontuar vários modelos em lote com agendamento em paralelo usando o Serviço Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="afd22-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="afd22-105">A solução pode ser usada como um modelo e pode ser generalizada para problemas diferentes.</span><span class="sxs-lookup"><span data-stu-id="afd22-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="afd22-106">Há uma implantação de referência para essa arquitetura de referência disponível no [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="afd22-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Pontuação em lote de modelos Python no Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="afd22-108">**Cenário**: A solução monitora a operação de um grande número de dispositivos em uma configuração de IoT, em que cada dispositivo envia leituras do sensor continuamente.</span><span class="sxs-lookup"><span data-stu-id="afd22-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="afd22-109">Assume-se que cada dispositivo é associado com modelos de detecção de anomalias pré-treinados que precisam ser usados para prever se uma série de medidas, agregadas em um intervalo de tempo predefinido, correspondem a uma anomalia ou não.</span><span class="sxs-lookup"><span data-stu-id="afd22-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="afd22-110">Em cenários do mundo real, isso seria um fluxo de leituras de sensor que precisariam ser filtrados e agregados antes de serem usados em treinamento ou pontuação em tempo real.</span><span class="sxs-lookup"><span data-stu-id="afd22-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="afd22-111">Para manter a simplicidade, essa solução usa o mesmo arquivo de dados na execução de trabalhos de pontuação.</span><span class="sxs-lookup"><span data-stu-id="afd22-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="afd22-112">Essa arquitetura de referência foi projetada para cargas de trabalho que são disparadas de forma agendada.</span><span class="sxs-lookup"><span data-stu-id="afd22-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="afd22-113">O processamento envolve as seguintes etapas:</span><span class="sxs-lookup"><span data-stu-id="afd22-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="afd22-114">Envie leituras do sensor para ingestão para os Hubs de Eventos do Azure.</span><span class="sxs-lookup"><span data-stu-id="afd22-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="afd22-115">Execute o processamento do fluxo e armazene os dados brutos.</span><span class="sxs-lookup"><span data-stu-id="afd22-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="afd22-116">Envie os dados para um cluster de Machine Learning que esteja pronto para começar a fazer o trabalho.</span><span class="sxs-lookup"><span data-stu-id="afd22-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="afd22-117">Cada nó no cluster executa um trabalho de pontuação para um sensor específico.</span><span class="sxs-lookup"><span data-stu-id="afd22-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="afd22-118">Execute o pipeline de pontuação, que executa os trabalhos de pontuação em paralelo usando scripts Python de Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="afd22-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="afd22-119">O pipeline é criado, publicado e agendado para ser executado em um intervalo de tempo predefinido.</span><span class="sxs-lookup"><span data-stu-id="afd22-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="afd22-120">Gere previsões e armazene-as no armazenamento de Blobs para consumo posterior.</span><span class="sxs-lookup"><span data-stu-id="afd22-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="afd22-121">Arquitetura</span><span class="sxs-lookup"><span data-stu-id="afd22-121">Architecture</span></span>

<span data-ttu-id="afd22-122">Essa arquitetura é formada pelos seguintes componentes:</span><span class="sxs-lookup"><span data-stu-id="afd22-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="afd22-123">[Hubs de Eventos do Azure][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="afd22-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="afd22-124">Esse serviço de ingestão de mensagens pode incluir milhões de mensagens de eventos por segundo.</span><span class="sxs-lookup"><span data-stu-id="afd22-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="afd22-125">Nesta arquitetura, os sensores enviam um fluxo de dados para o hub de eventos.</span><span class="sxs-lookup"><span data-stu-id="afd22-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="afd22-126">[Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="afd22-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="afd22-127">Um mecanismo de processamento de eventos.</span><span class="sxs-lookup"><span data-stu-id="afd22-127">An event-processing engine.</span></span> <span data-ttu-id="afd22-128">Um trabalho do Stream Analytics lê os fluxos de dados do hub de eventos e executa o processamento de fluxo.</span><span class="sxs-lookup"><span data-stu-id="afd22-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="afd22-129">[Banco de Dados SQL do Azure][sql-database].</span><span class="sxs-lookup"><span data-stu-id="afd22-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="afd22-130">Os dados das leituras do sensor são carregados no Banco de Dados SQL.</span><span class="sxs-lookup"><span data-stu-id="afd22-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="afd22-131">SQL é uma maneira familiar para armazenar os dados transmitidos e processados (que são estruturados e tabulares), mas outros armazenamentos de dados podem ser usados.</span><span class="sxs-lookup"><span data-stu-id="afd22-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="afd22-132">[Serviço do Azure Machine Learning][amls].</span><span class="sxs-lookup"><span data-stu-id="afd22-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="afd22-133">Machine Learning é um serviço de nuvem para treinamento, pontuação, implantação e gerenciamento de modelos de machine learning em escala.</span><span class="sxs-lookup"><span data-stu-id="afd22-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="afd22-134">No contexto de pontuação de lote, o Machine Learning cria um cluster de máquinas virtuais sob demanda com uma opção de dimensionamento automático, em que cada nó no cluster executa um trabalho de pontuação para um sensor específico.</span><span class="sxs-lookup"><span data-stu-id="afd22-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="afd22-135">Os trabalhos de pontuação são executados em paralelo como etapas de script do Python que são enfileiradas e gerenciadas pelo Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="afd22-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="afd22-136">Essas etapas são parte de um pipeline do Machine Learning que é criado, publicado e agendado para ser executado em um intervalo predefinido de tempo.</span><span class="sxs-lookup"><span data-stu-id="afd22-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="afd22-137">[Armazenamento de Blobs do Azure][storage].</span><span class="sxs-lookup"><span data-stu-id="afd22-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="afd22-138">Os contêineres de blob são usados para armazenar os modelos pré-treinados, os dados e as previsões de saída.</span><span class="sxs-lookup"><span data-stu-id="afd22-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="afd22-139">Os modelos são carregados no Armazenamento de Blobs no notebook [01_create_resources.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="afd22-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="afd22-140">Esses modelos de [SVM de classe única][one-class-svm] são treinados com dados que representam valores de sensores diferentes em dispositivos diferentes.</span><span class="sxs-lookup"><span data-stu-id="afd22-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="afd22-141">A solução pressupõe que os valores de dados foram agregados em um intervalo fixo de tempo.</span><span class="sxs-lookup"><span data-stu-id="afd22-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="afd22-142">[Registro de Contêiner do Azure][acr].</span><span class="sxs-lookup"><span data-stu-id="afd22-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="afd22-143">O [script][pyscript] de pontuação em Python é executado em contêineres do Docker que são criados em cada nó do cluster, onde ele lê os dados de sensor relevantes, gera previsões e as armazena no Armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="afd22-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="afd22-144">Considerações sobre o desempenho</span><span class="sxs-lookup"><span data-stu-id="afd22-144">Performance considerations</span></span>

<span data-ttu-id="afd22-145">Para modelos Python normais, é geralmente aceito que as CPUs são suficientes para lidar com a carga de trabalho.</span><span class="sxs-lookup"><span data-stu-id="afd22-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="afd22-146">Esta arquitetura usa CPUs.</span><span class="sxs-lookup"><span data-stu-id="afd22-146">This architecture uses CPUs.</span></span> <span data-ttu-id="afd22-147">No entanto, para [cargas de trabalho de aprendizado profundo][deep], GPUs geralmente superam as CPUs por uma quantidade considerável &mdash; um cluster considerável de CPUs normalmente é necessário para obter um desempenho comparável.</span><span class="sxs-lookup"><span data-stu-id="afd22-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="afd22-148">Paralelização entre VMs em vez de núcleos</span><span class="sxs-lookup"><span data-stu-id="afd22-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="afd22-149">Ao executar processos de pontuação de vários modelos em modo de lote, os trabalhos precisam ser colocados em paralelo entre VMs.</span><span class="sxs-lookup"><span data-stu-id="afd22-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="afd22-150">Há duas abordagens possíveis:</span><span class="sxs-lookup"><span data-stu-id="afd22-150">Two approaches are possible:</span></span>

* <span data-ttu-id="afd22-151">Criar um cluster maior usando VMs de baixo custo.</span><span class="sxs-lookup"><span data-stu-id="afd22-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="afd22-152">Criar um cluster menor usando VMs de alto desempenho com mais núcleos disponíveis em cada uma.</span><span class="sxs-lookup"><span data-stu-id="afd22-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="afd22-153">Em geral, a pontuação de modelos Python padrão não é tão exigente quanto a pontuação de modelos de aprendizado profundo, e um pequeno cluster deve ser capaz de lidar com um grande número de modelos em fila eficientemente.</span><span class="sxs-lookup"><span data-stu-id="afd22-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="afd22-154">Você pode aumentar o número de nós de cluster de acordo com o aumento dos tamanhos do conjunto de dados.</span><span class="sxs-lookup"><span data-stu-id="afd22-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="afd22-155">Por questões de conveniência neste cenário, uma tarefa de pontuação é enviada dentro de uma única etapa de pipeline do Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="afd22-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="afd22-156">No entanto, pode ser mais eficiente pontuar várias partes de dados dentro da mesma etapa de pipeline.</span><span class="sxs-lookup"><span data-stu-id="afd22-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="afd22-157">Nesses casos, escreva código personalizado para ler vários conjuntos de dados e executar o script de pontuação para eles durante uma mesma execução de etapa.</span><span class="sxs-lookup"><span data-stu-id="afd22-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="afd22-158">Considerações de gerenciamento</span><span class="sxs-lookup"><span data-stu-id="afd22-158">Management considerations</span></span>

- <span data-ttu-id="afd22-159">**Monitorar trabalhos**.</span><span class="sxs-lookup"><span data-stu-id="afd22-159">**Monitor jobs**.</span></span> <span data-ttu-id="afd22-160">É importante monitorar o progresso de trabalhos em execução, mas pode ser um desafio monitorá-los em um cluster de nós ativos.</span><span class="sxs-lookup"><span data-stu-id="afd22-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="afd22-161">Para inspecionar o estado de nós no cluster, use o [Portal do Azure][portal] para gerenciar o [workspace do machine learning][ml-workspace].</span><span class="sxs-lookup"><span data-stu-id="afd22-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="afd22-162">Se um nó estiver inativo ou se um trabalho falhar, os logs de erro serão salvos no armazenamento de blobs e também poderão ser acessados na seção Pipelines.</span><span class="sxs-lookup"><span data-stu-id="afd22-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="afd22-163">Para um monitoramento mais avançado, conecte os logs ao [Application Insights][app-insights], ou execute processos separados para sondar o estado do cluster e de seus trabalhos.</span><span class="sxs-lookup"><span data-stu-id="afd22-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="afd22-164">**Registro em log**.</span><span class="sxs-lookup"><span data-stu-id="afd22-164">**Logging**.</span></span> <span data-ttu-id="afd22-165">Os logs do Serviço Machine Learning registram todos os stdout/stderr da conta do Armazenamento do Azure associada.</span><span class="sxs-lookup"><span data-stu-id="afd22-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="afd22-166">Para navegar facilmente nos arquivos de log, use uma ferramenta de navegação de armazenamento, como o [Gerenciador de Armazenamento do Azure][explorer].</span><span class="sxs-lookup"><span data-stu-id="afd22-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="afd22-167">Considerações de custo</span><span class="sxs-lookup"><span data-stu-id="afd22-167">Cost considerations</span></span>

<span data-ttu-id="afd22-168">Os componentes mais caros usados nesta arquitetura de referência são os recursos de computação.</span><span class="sxs-lookup"><span data-stu-id="afd22-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="afd22-169">O tamanho do cluster de cálculo é aumentado e reduzido dependendo dos trabalhos na fila.</span><span class="sxs-lookup"><span data-stu-id="afd22-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="afd22-170">Habilite o dimensionamento automático por meio de programação com o SDK do Python, modificando a configuração de provisionamento da computação.</span><span class="sxs-lookup"><span data-stu-id="afd22-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="afd22-171">Ou use a [CLI do Azure][cli] para definir os parâmetros de dimensionamento automático do cluster.</span><span class="sxs-lookup"><span data-stu-id="afd22-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="afd22-172">Para trabalho que não exige processamento imediato, configure a fórmula de dimensionamento automático a fim de definir o estado padrão (mínimo) como um cluster sem nós.</span><span class="sxs-lookup"><span data-stu-id="afd22-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="afd22-173">Com essa configuração, o cluster começa com zero nós e só pode ser escalado verticalmente quando detecta os trabalhos na fila.</span><span class="sxs-lookup"><span data-stu-id="afd22-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="afd22-174">Se o processo de pontuação do lote acontecer apenas algumas vezes por dia, essa configuração permitirá uma economia considerável.</span><span class="sxs-lookup"><span data-stu-id="afd22-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="afd22-175">Talvez o dimensionamento automático não seja apropriado para trabalhos em lote que aconteçam muito próximos uns dos outros.</span><span class="sxs-lookup"><span data-stu-id="afd22-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="afd22-176">O tempo de ativação e desativação de um cluster também incorre em um custo, portanto, se uma carga de trabalho do lote começar apenas alguns minutos após o término do trabalho anterior, talvez seja mais econômico manter o cluster em execução entre os trabalhos.</span><span class="sxs-lookup"><span data-stu-id="afd22-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="afd22-177">Isso depende da frequência de agendamento dos processos de pontuação, com alta frequência (a cada hora, por exemplo) ou com baixa frequência (uma vez por mês, por exemplo).</span><span class="sxs-lookup"><span data-stu-id="afd22-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="afd22-178">Implantação</span><span class="sxs-lookup"><span data-stu-id="afd22-178">Deployment</span></span>

<span data-ttu-id="afd22-179">Para implantar essa arquitetura de referência, execute as etapas descritas no [repositório do GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="afd22-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
