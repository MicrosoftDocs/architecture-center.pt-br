---
title: Treinamento distribuído de modelos de aprendizado profundo no Azure
description: Essa arquitetura de referência mostra como realizar treinamento distribuído de modelos de aprendizado profundo em clusters de VMs habilitadas para GPU usando IA do Lote do Azure.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: pt-BR
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307737"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="1381d-103">Treinamento distribuído de modelos de aprendizado profundo no Azure</span><span class="sxs-lookup"><span data-stu-id="1381d-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="1381d-104">Essa arquitetura de referência mostra como realizar o treinamento distribuído de modelos de aprendizado profundo em clusters de VMs habilitadas para GPU.</span><span class="sxs-lookup"><span data-stu-id="1381d-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="1381d-105">O cenário é a classificação de imagens, mas a solução pode ser adaptada para outros cenários de aprendizado profundo, como detecção e segmentação de objetos.</span><span class="sxs-lookup"><span data-stu-id="1381d-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="1381d-106">Há uma implantação de referência para essa arquitetura de referência disponível no [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="1381d-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Arquitetura para aprendizado profundo distribuído][0]

<span data-ttu-id="1381d-108">**Cenário**: A classificação de imagens é uma técnica amplamente aplicada na pesquisa visual computacional e é geralmente realizada com o treinamento de uma CNN (rede neural convolucional).</span><span class="sxs-lookup"><span data-stu-id="1381d-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="1381d-109">Para modelos muito grandes com grandes conjuntos de dados, o processo de treinamento pode levar semanas ou meses em uma única GPU.</span><span class="sxs-lookup"><span data-stu-id="1381d-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="1381d-110">Em algumas situações, os modelos são tão grandes que não é possível encaixar tamanhos de lote razoáveis na GPU.</span><span class="sxs-lookup"><span data-stu-id="1381d-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="1381d-111">O uso do treinamento distribuído nessas situações pode reduzir o tempo de treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="1381d-112">Neste cenário específico, um [modelo CNN ResNet50][resnet] é treinado usando [Horovod][horovod] no [conjunto de dados Imagenet][imagenet] e em dados sintéticos.</span><span class="sxs-lookup"><span data-stu-id="1381d-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="1381d-113">A implementação de referência mostra como realizar essa tarefa usando três das mais populares estruturas de aprendizado profundo: TensorFlow, Keras e PyTorch.</span><span class="sxs-lookup"><span data-stu-id="1381d-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="1381d-114">Há várias maneiras de treinar um modelo de aprendizado profundo de forma distribuída, incluindo abordagens de dados em paralelo e modelo em paralelo baseadas em atualizações síncronas ou assíncronas.</span><span class="sxs-lookup"><span data-stu-id="1381d-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="1381d-115">Atualmente, o cenário mais comum é formado por dados em paralelo com atualizações síncronas.</span><span class="sxs-lookup"><span data-stu-id="1381d-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="1381d-116">Essa abordagem é mais fácil de implementar e é suficiente para a maioria dos casos de uso.</span><span class="sxs-lookup"><span data-stu-id="1381d-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="1381d-117">No treinamento distribuído de dados em paralelo com atualizações síncronas, o modelo é replicado em *n* dispositivos de hardware.</span><span class="sxs-lookup"><span data-stu-id="1381d-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="1381d-118">Um minilote de exemplos de treinamento é dividido em *n* microlotes.</span><span class="sxs-lookup"><span data-stu-id="1381d-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="1381d-119">Cada dispositivo executa as passagens para frente e para trás de um microlote.</span><span class="sxs-lookup"><span data-stu-id="1381d-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="1381d-120">Quando um dispositivo conclui o processo, ele compartilha as atualizações com os demais dispositivos.</span><span class="sxs-lookup"><span data-stu-id="1381d-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="1381d-121">Esses valores são usados para calcular os pesos atualizados de todo o minilote, e os pesos são sincronizados em todos os modelos.</span><span class="sxs-lookup"><span data-stu-id="1381d-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="1381d-122">Esse cenário é abordado no repositório do [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="1381d-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Treinamento distribuído de dados em paralelo][1]

<span data-ttu-id="1381d-124">Essa arquitetura também pode ser usada em atualizações assíncronas ou de modelos em paralelo.</span><span class="sxs-lookup"><span data-stu-id="1381d-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="1381d-125">No treinamento distribuído do modelo em paralelo, o modelo é dividido em *n* dispositivos de hardware, com cada dispositivo mantendo uma parte do modelo.</span><span class="sxs-lookup"><span data-stu-id="1381d-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="1381d-126">Na implementação mais simples, cada dispositivo pode conter uma camada da rede e as informações são passadas entre os dispositivos durante a passagem para frente e para trás.</span><span class="sxs-lookup"><span data-stu-id="1381d-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="1381d-127">Redes neurais maiores podem ser treinadas dessa maneira, mas à custa do desempenho, já que os dispositivos aguardam constantemente um pelo outro para concluir a passagem para frente ou para trás.</span><span class="sxs-lookup"><span data-stu-id="1381d-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="1381d-128">Algumas técnicas avançadas tentam aliviar parcialmente esse problema usando gradientes sintéticos.</span><span class="sxs-lookup"><span data-stu-id="1381d-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="1381d-129">As etapas do treinamento são:</span><span class="sxs-lookup"><span data-stu-id="1381d-129">The steps for training are:</span></span>

1. <span data-ttu-id="1381d-130">Crie scripts que serão executados no cluster e treine seu modelo. Em seguida, transfira-os para o armazenamento de arquivos.</span><span class="sxs-lookup"><span data-stu-id="1381d-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="1381d-131">Grave os dados no Armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="1381d-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="1381d-132">Crie um servidor de arquivos de IA do Lote e baixe os dados do Armazenamento de Blobs para ele.</span><span class="sxs-lookup"><span data-stu-id="1381d-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="1381d-133">Crie os contêineres do Docker para cada framework de aprendizado profundo e transfira-os para um registro de contêiner (Hub do Docker).</span><span class="sxs-lookup"><span data-stu-id="1381d-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="1381d-134">Crie um pool de IA do Lote que também monte o servidor de arquivos de IA do Lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="1381d-135">Enviar trabalhos.</span><span class="sxs-lookup"><span data-stu-id="1381d-135">Submit jobs.</span></span> <span data-ttu-id="1381d-136">Cada um deles efetua pull da imagem e dos scripts apropriados do Docker.</span><span class="sxs-lookup"><span data-stu-id="1381d-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="1381d-137">Depois que o trabalho for concluído, grave todos os resultados no armazenamento de arquivos.</span><span class="sxs-lookup"><span data-stu-id="1381d-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="1381d-138">Arquitetura</span><span class="sxs-lookup"><span data-stu-id="1381d-138">Architecture</span></span>

<span data-ttu-id="1381d-139">Essa arquitetura é formada pelos componentes a seguir.</span><span class="sxs-lookup"><span data-stu-id="1381d-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="1381d-140">A **[IA do Lote do Azure][batch-ai]** desempenha o papel principal nesta arquitetura, escalando os recursos verticalmente ou reduzindo-os verticalmente, dependendo da necessidade.</span><span class="sxs-lookup"><span data-stu-id="1381d-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="1381d-141">A IA do Lote é um serviço que ajuda a provisionar e gerenciar clusters de VMs, agendar trabalhos, coletar resultados, dimensionar recursos, lidar com falhas e criar o armazenamento apropriado.</span><span class="sxs-lookup"><span data-stu-id="1381d-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="1381d-142">Ela oferece suporte a VMs habilitadas para GPU para cargas de trabalho de aprendizado profundo.</span><span class="sxs-lookup"><span data-stu-id="1381d-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="1381d-143">Um SDK do Python e uma interface de linha de comando (CLI) estão disponíveis para a IA do Lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="1381d-144">Os serviços de IA do Lote do Azure serão desativados em março de 2019 e seu treinamento em escala, assim como suas funcionalidades de pontuação, já estão disponíveis no [Serviço do Azure Machine Learning][amls].</span><span class="sxs-lookup"><span data-stu-id="1381d-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="1381d-145">Essa arquitetura de referência será atualizada em breve para uso de Machine Learning, que oferece um destino de computação gerenciada chamado [Computação do Machine Learning do Azure][aml-compute] para treinamento, implantação e pontuação de modelos de aprendizado de máquina.</span><span class="sxs-lookup"><span data-stu-id="1381d-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="1381d-146">O **[Armazenamento de Blobs][azure-blob]** é usado para preparar os dados.</span><span class="sxs-lookup"><span data-stu-id="1381d-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="1381d-147">Esses dados são baixados para um servidor de arquivos da IA do Lote durante o treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="1381d-148">Os **[Arquivos do Azure][files]** são usados para armazenar os scripts, os logs e os resultados finais do treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="1381d-149">O armazenamento de arquivos funciona bem para armazenar logs e scripts, mas não é tão eficiente quanto o Armazenamento de Blobs. Por isso, não deve ser usado para tarefas que exigem muitos dados.</span><span class="sxs-lookup"><span data-stu-id="1381d-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="1381d-150">O **[Servidor de arquivos de IA do Lote][batch-ai-files]** é um compartilhamento NFS de nó único usado nesta arquitetura para armazenar os dados de treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="1381d-151">A IA do Lote cria um compartilhamento NFS e monta-o no cluster.</span><span class="sxs-lookup"><span data-stu-id="1381d-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="1381d-152">Os servidores de arquivos da IA do Lote são a maneira recomendada de fornecer dados ao cluster com a taxa de transferência necessária.</span><span class="sxs-lookup"><span data-stu-id="1381d-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="1381d-153">O **[Hub do Docker][docker]** é usado para armazenar a imagem do Docker que a IA do Lote usa para executar o treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="1381d-154">O Docker Hub foi escolhido para essa arquitetura por ser fácil de usar e ser o repositório de imagens padrão para usuários do Docker.</span><span class="sxs-lookup"><span data-stu-id="1381d-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="1381d-155">O [Registro de Contêiner do Azure][acr] também pode ser usado.</span><span class="sxs-lookup"><span data-stu-id="1381d-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="1381d-156">Considerações sobre o desempenho</span><span class="sxs-lookup"><span data-stu-id="1381d-156">Performance considerations</span></span>

<span data-ttu-id="1381d-157">O Azure fornece quatro [tipos de VM habilitados para GPU][gpu] adequados para o treinamento de modelos de aprendizado profundo.</span><span class="sxs-lookup"><span data-stu-id="1381d-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="1381d-158">Eles variam em preço e velocidade, que podem ser baixos e altos, da seguinte forma:</span><span class="sxs-lookup"><span data-stu-id="1381d-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="1381d-159">**Série de VMs do Azure**</span><span class="sxs-lookup"><span data-stu-id="1381d-159">**Azure VM series**</span></span> | <span data-ttu-id="1381d-160">**GPU NVIDIA**</span><span class="sxs-lookup"><span data-stu-id="1381d-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="1381d-161">NC</span><span class="sxs-lookup"><span data-stu-id="1381d-161">NC</span></span>                  | <span data-ttu-id="1381d-162">K80</span><span class="sxs-lookup"><span data-stu-id="1381d-162">K80</span></span>            |
| <span data-ttu-id="1381d-163">ND</span><span class="sxs-lookup"><span data-stu-id="1381d-163">ND</span></span>                  | <span data-ttu-id="1381d-164">P40</span><span class="sxs-lookup"><span data-stu-id="1381d-164">P40</span></span>            |
| <span data-ttu-id="1381d-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="1381d-165">NCv2</span></span>                | <span data-ttu-id="1381d-166">P100</span><span class="sxs-lookup"><span data-stu-id="1381d-166">P100</span></span>           |
| <span data-ttu-id="1381d-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="1381d-167">NCv3</span></span>                | <span data-ttu-id="1381d-168">V100</span><span class="sxs-lookup"><span data-stu-id="1381d-168">V100</span></span>           |

<span data-ttu-id="1381d-169">Recomendamos dimensionar seu treinamento verticalmente antes de dimensioná-lo horizontalmente. Por exemplo, experimente um único V100 antes de experimentar um cluster de K80s.</span><span class="sxs-lookup"><span data-stu-id="1381d-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="1381d-170">O gráfico a seguir mostra as diferenças de desempenho para diferentes tipos de GPU baseados em [testes de parâmetro de comparação][benchmark] realizados usando o TensorFlow e Horovod na IA do Lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="1381d-171">O gráfico mostra a taxa de transferência de 32 clusters GPU em vários modelos, em diferentes tipos de GPU e versões de MPI.</span><span class="sxs-lookup"><span data-stu-id="1381d-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="1381d-172">Foram implementados modelos no TensorFlow 1.9</span><span class="sxs-lookup"><span data-stu-id="1381d-172">Models were implemented in TensorFlow 1.9</span></span>

![Resultados da taxa de transferência para modelos do TensorFlow em clusters GPU][2]

<span data-ttu-id="1381d-174">Cada série de VMs exibida na tabela anterior inclui uma configuração com o InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="1381d-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="1381d-175">Use as configurações do InfiniBand ao executar o treinamento distribuído e obtenha uma comunicação mais rápida entre os nós.</span><span class="sxs-lookup"><span data-stu-id="1381d-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="1381d-176">O InfiniBand também aumenta a eficiência do dimensionamento do treinamento para os frameworks que podem aproveitá-lo.</span><span class="sxs-lookup"><span data-stu-id="1381d-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="1381d-177">Para obter detalhes, confira o [parâmetro de comparação][benchmark] do Infiniband.</span><span class="sxs-lookup"><span data-stu-id="1381d-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="1381d-178">Embora a IA do Lote possa montar o armazenamento de Blobs usando o adaptador [blobfuse][blobfuse], não recomendamos o uso do Armazenamento de Blobs dessa maneira para treinamento distribuído, já que o desempenho não é bom o suficiente para tratar da taxa de transferência necessária.</span><span class="sxs-lookup"><span data-stu-id="1381d-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="1381d-179">Em vez disso, mova os dados para um servidor de arquivos de IA do Lote, conforme mostrado no diagrama da arquitetura.</span><span class="sxs-lookup"><span data-stu-id="1381d-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="1381d-180">Considerações sobre escalabilidade</span><span class="sxs-lookup"><span data-stu-id="1381d-180">Scalability considerations</span></span>

<span data-ttu-id="1381d-181">A eficiência do dimensionamento do treinamento distribuído é sempre menor que 100%, devido à sobrecarga da rede &mdash; a sincronização do modelo inteiro entre os dispositivos forma um gargalo.</span><span class="sxs-lookup"><span data-stu-id="1381d-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="1381d-182">Portanto, o treinamento distribuído é mais adequado para modelos grandes que não podem ser treinados usando um tamanho de lote razoável em uma única GPU ou para problemas que não podem ser resolvidos com a distribuição do modelo de maneira simples e paralela.</span><span class="sxs-lookup"><span data-stu-id="1381d-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="1381d-183">O treinamento distribuído não é recomendado para a execução de pesquisas de hiperparâmetro.</span><span class="sxs-lookup"><span data-stu-id="1381d-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="1381d-184">A eficiência do dimensionamento afeta o desempenho e torna a abordagem distribuída menos eficiente do que o treinamento separado de várias configurações de modelo.</span><span class="sxs-lookup"><span data-stu-id="1381d-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="1381d-185">Uma maneira de aumentar a eficiência do dimensionamento é aumentar o tamanho do lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="1381d-186">No entanto, isso deve ser feito com cuidado, já que aumentar o tamanho do lote sem ajustar os demais parâmetros pode prejudicar o desempenho final do modelo.</span><span class="sxs-lookup"><span data-stu-id="1381d-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="1381d-187">Considerações de armazenamento</span><span class="sxs-lookup"><span data-stu-id="1381d-187">Storage considerations</span></span>

<span data-ttu-id="1381d-188">Ao treinar modelos de aprendizado profundo, um aspecto frequentemente negligenciado é o local onde os dados são armazenados.</span><span class="sxs-lookup"><span data-stu-id="1381d-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="1381d-189">Se o armazenamento for muito lento para acompanhar as demandas das GPUs, o desempenho do treinamento poderá diminuir.</span><span class="sxs-lookup"><span data-stu-id="1381d-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="1381d-190">A IA do Lote é compatível com muitas soluções de armazenamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="1381d-191">Essa arquitetura usa um servidor de arquivos da IA do Lote porque oferece a melhor relação entre facilidade de uso e desempenho.</span><span class="sxs-lookup"><span data-stu-id="1381d-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="1381d-192">Para ter um desempenho melhor, carregue os dados localmente.</span><span class="sxs-lookup"><span data-stu-id="1381d-192">For best performance, load the data locally.</span></span> <span data-ttu-id="1381d-193">No entanto, isso pode ser complicado porque todos os nós devem fazer o download dos dados do Armazenamento de Blobs e, com o conjunto de dados do ImageNet, isso pode levar horas.</span><span class="sxs-lookup"><span data-stu-id="1381d-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="1381d-194">O [Armazenamento de Blobs do Azure Premium][blob] (visualização pública limitada) é outra boa opção a ser considerada.</span><span class="sxs-lookup"><span data-stu-id="1381d-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="1381d-195">Não monte o armazenamento de Blobs e de arquivos como repositórios de dados para o treinamento distribuído.</span><span class="sxs-lookup"><span data-stu-id="1381d-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="1381d-196">Eles são muito lentos e atrapalham o desempenho do treinamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="1381d-197">Considerações de segurança</span><span class="sxs-lookup"><span data-stu-id="1381d-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="1381d-198">Restringir acesso ao Armazenamento de Blobs do Azure</span><span class="sxs-lookup"><span data-stu-id="1381d-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="1381d-199">Essa arquitetura usa [chaves de conta de armazenamento][security-guide] para acessar o armazenamento de Blobs.</span><span class="sxs-lookup"><span data-stu-id="1381d-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="1381d-200">Para obter mais controle e proteção, considere o uso de uma SAS (Assinatura de Acesso Compartilhado).</span><span class="sxs-lookup"><span data-stu-id="1381d-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="1381d-201">Isso concede acesso limitado a objetos no armazenamento, sem a necessidade de codificar as chaves da conta ou salvá-las em um texto não criptografado.</span><span class="sxs-lookup"><span data-stu-id="1381d-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="1381d-202">Usar uma SAS também ajuda a garantir que a conta de armazenamento tenha uma governança adequada e que o acesso seja concedido somente às pessoas certas.</span><span class="sxs-lookup"><span data-stu-id="1381d-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="1381d-203">Para cenários com os dados mais confidenciais, verifique se todas as chaves de armazenamento estão protegidas, pois essas chaves concedem acesso completo a todos os dados de entrada e de saída da carga de trabalho.</span><span class="sxs-lookup"><span data-stu-id="1381d-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="1381d-204">Criptografar dados em repouso e em movimento</span><span class="sxs-lookup"><span data-stu-id="1381d-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="1381d-205">Em cenários que usam dados confidenciais, criptografe os dados em repouso &mdash; ou seja, os dados no armazenamento.</span><span class="sxs-lookup"><span data-stu-id="1381d-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="1381d-206">Sempre que os dados forem movidos de um local para o próximo, use SSL para proteger a transferência de dados.</span><span class="sxs-lookup"><span data-stu-id="1381d-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="1381d-207">Para saber mais, confira o [Guia de segurança de Armazenamento do Azure][security-guide].</span><span class="sxs-lookup"><span data-stu-id="1381d-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="1381d-208">Proteger dados em uma rede virtual</span><span class="sxs-lookup"><span data-stu-id="1381d-208">Secure data in a virtual network</span></span>

<span data-ttu-id="1381d-209">Em implantações de produção, considere implantar o cluster da IA do Lote em uma sub-rede de uma rede virtual que você especificar.</span><span class="sxs-lookup"><span data-stu-id="1381d-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="1381d-210">Isso permite que os nós de computação no cluster se comuniquem com segurança com outras máquinas virtuais ou com uma rede local.</span><span class="sxs-lookup"><span data-stu-id="1381d-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="1381d-211">Você também pode usar [pontos de extremidade de serviço][endpoints] com o armazenamento de blobs para conceder acesso de uma rede virtual ou usar um NFS de nó único dentro da rede virtual com a IA do Lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="1381d-212">Considerações de monitoramento</span><span class="sxs-lookup"><span data-stu-id="1381d-212">Monitoring considerations</span></span>

<span data-ttu-id="1381d-213">Durante a execução do seu trabalho, é importante monitorar o progresso e certificar-se de que as coisas estão funcionando conforme o esperado.</span><span class="sxs-lookup"><span data-stu-id="1381d-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="1381d-214">No entanto, pode ser um desafio monitorar um cluster de nós ativos.</span><span class="sxs-lookup"><span data-stu-id="1381d-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="1381d-215">Os servidores de arquivos da IA do Lote podem ser gerenciados pelo portal do Azure ou pela [CLI do Azure][cli] e pelo SDK do Python.</span><span class="sxs-lookup"><span data-stu-id="1381d-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="1381d-216">Para ter uma ideia do estado geral do cluster, navegue até a **IA do Lote** no portal do Azure para inspecionar o estado dos nós de cluster.</span><span class="sxs-lookup"><span data-stu-id="1381d-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="1381d-217">Se um nó estiver inativo ou se um trabalho falhar, os logs de erro serão salvos no armazenamento de blobs e também poderão ser acessados no portal do Azure em **Trabalhos**.</span><span class="sxs-lookup"><span data-stu-id="1381d-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="1381d-218">É possível melhorar ainda mais o monitoramento conectando os logs ao [Azure Application Insights][ai] ou executando processos separados para sondar o estado do cluster da IA do Lote e seus trabalhos.</span><span class="sxs-lookup"><span data-stu-id="1381d-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="1381d-219">A IA do Lote registra automaticamente todos os stdout/stderr para a conta de armazenamento de blobs associada.</span><span class="sxs-lookup"><span data-stu-id="1381d-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="1381d-220">O uso de uma ferramenta de navegação de armazenamento, como o [Gerenciador de Armazenamento do Azure][storage-explorer], fornecerá uma experiência muito mais fácil para navegação em arquivos de log.</span><span class="sxs-lookup"><span data-stu-id="1381d-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="1381d-221">Também é possível transmitir os logs para cada trabalho.</span><span class="sxs-lookup"><span data-stu-id="1381d-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="1381d-222">Para obter detalhes sobre essa opção, confira as etapas de desenvolvimento no [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="1381d-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="1381d-223">Implantação</span><span class="sxs-lookup"><span data-stu-id="1381d-223">Deployment</span></span>

<span data-ttu-id="1381d-224">Há uma implantação de referência para essa arquitetura disponível no [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="1381d-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="1381d-225">Siga as etapas descritas para executar o treinamento distribuído de modelos de aprendizado profundo em clusters de VMs habilitadas para GPU.</span><span class="sxs-lookup"><span data-stu-id="1381d-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="1381d-226">Próximas etapas</span><span class="sxs-lookup"><span data-stu-id="1381d-226">Next steps</span></span>

<span data-ttu-id="1381d-227">A saída dessa arquitetura é um modelo treinado salvo no armazenamento de blobs.</span><span class="sxs-lookup"><span data-stu-id="1381d-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="1381d-228">É possível operacionalizar esse modelo para pontuação em tempo real ou pontuação do lote.</span><span class="sxs-lookup"><span data-stu-id="1381d-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="1381d-229">Para obter mais informações, confira as seguintes arquiteturas de referência:</span><span class="sxs-lookup"><span data-stu-id="1381d-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="1381d-230">[Pontuação em tempo real do Python Scikit-Learn e modelos de aprendizado profundo no Azure][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="1381d-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="1381d-231">[Pontuação em lote para modelos de aprendizado profundo do Azure][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="1381d-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning