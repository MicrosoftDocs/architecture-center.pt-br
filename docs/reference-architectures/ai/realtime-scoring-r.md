---
title: Pontuação em tempo real dos modelos do Machine Learning em R
description: Implemente um serviço de previsão em tempo real em R usando o Machine Learning Server em execução no Serviço de Kubernetes do Azure (AKS).
author: njray
ms.date: 12/12/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 5f3cc62c81c9ef9e5c3c27b1d66badd3e481c228
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 04/18/2019
ms.locfileid: "59740418"
---
# <a name="real-time-scoring-of-r-machine-learning-models-on-azure"></a><span data-ttu-id="248a8-103">Pontuação em tempo real dos modelos do Machine Learning em R no Azure</span><span class="sxs-lookup"><span data-stu-id="248a8-103">Real-time scoring of R machine learning models on Azure</span></span>

<span data-ttu-id="248a8-104">Esta arquitetura de referência mostra como implementar um serviço de previsão em tempo real (síncrono) em R usando o Microsoft Machine Learning Server em execução no Serviço de Kubernetes do Azure (AKS).</span><span class="sxs-lookup"><span data-stu-id="248a8-104">This reference architecture shows how to implement a real-time (synchronous) prediction service in R using Microsoft Machine Learning Server running in Azure Kubernetes Service (AKS).</span></span> <span data-ttu-id="248a8-105">Essa arquitetura pretende ser genérica e adequada para qualquer modelo de previsão compilado em R que você queria implantar como um serviço em tempo real.</span><span class="sxs-lookup"><span data-stu-id="248a8-105">This architecture is intended to be generic and suited for any predictive model built in R that you want to deploy as a real-time service.</span></span> <span data-ttu-id="248a8-106">**[Implante essa solução][github]**.</span><span class="sxs-lookup"><span data-stu-id="248a8-106">**[Deploy this solution][github]**.</span></span>

## <a name="architecture"></a><span data-ttu-id="248a8-107">Arquitetura</span><span class="sxs-lookup"><span data-stu-id="248a8-107">Architecture</span></span>

![Pontuação em tempo real dos modelos do Machine Learning em R no Azure][0]

<span data-ttu-id="248a8-109">Essa arquitetura de referência usa uma abordagem baseada em contêiner.</span><span class="sxs-lookup"><span data-stu-id="248a8-109">This reference architecture takes a container-based approach.</span></span> <span data-ttu-id="248a8-110">Uma imagem do Docker é compilada contendo o R, bem como os vários artefatos necessários para pontuar novos dados.</span><span class="sxs-lookup"><span data-stu-id="248a8-110">A Docker image is built containing R, as well as the various artifacts needed to score new data.</span></span> <span data-ttu-id="248a8-111">Isso inclui o próprio objeto de modelo e um script de pontuação.</span><span class="sxs-lookup"><span data-stu-id="248a8-111">These include the model object itself and a scoring script.</span></span> <span data-ttu-id="248a8-112">Essa imagem é enviada por push para um registro do Docker hospedado no Azure e, em seguida, implantado em um cluster Kubernetes, também no Azure.</span><span class="sxs-lookup"><span data-stu-id="248a8-112">This image is pushed to a Docker registry hosted in Azure, and then deployed to a Kubernetes cluster, also in Azure.</span></span>

<span data-ttu-id="248a8-113">A arquitetura desse fluxo de trabalho inclui os componentes a seguir.</span><span class="sxs-lookup"><span data-stu-id="248a8-113">The architecture of this workflow includes the following components.</span></span>

- <span data-ttu-id="248a8-114">O **[Registro de Contêiner do Azure][acr]** é usado para armazenar as imagens para esse fluxo de trabalho.</span><span class="sxs-lookup"><span data-stu-id="248a8-114">**[Azure Container Registry][acr]** is used to store the images for this workflow.</span></span> <span data-ttu-id="248a8-115">Os registros criados com o Registro de Contêiner podem ser gerenciados por meio da [API do Docker Registry V2][docker] padrão e o cliente.</span><span class="sxs-lookup"><span data-stu-id="248a8-115">Registries created with Container Registry can be managed via the standard [Docker Registry V2 API][docker] and client.</span></span>

- <span data-ttu-id="248a8-116">O **[Serviço de Kubernetes do Azure][aks]** é usado para hospedar a implantação e o serviço.</span><span class="sxs-lookup"><span data-stu-id="248a8-116">**[Azure Kubernetes Service][aks]** is used to host the deployment and service.</span></span> <span data-ttu-id="248a8-117">Clusters criados com o AKS podem ser gerenciados usando a [API do Kubernetes][k-api] padrão e o cliente (kubectl).</span><span class="sxs-lookup"><span data-stu-id="248a8-117">Clusters created with AKS can be managed using the standard [Kubernetes API][k-api] and client (kubectl).</span></span>

- <span data-ttu-id="248a8-118">O **[Microsoft Machine Learning Server][mmls]** é usado para definir a API REST para o serviço e inclui [Operacionalização do Modelo][operationalization].</span><span class="sxs-lookup"><span data-stu-id="248a8-118">**[Microsoft Machine Learning Server][mmls]** is used to define the REST API for the service and includes [Model Operationalization][operationalization].</span></span> <span data-ttu-id="248a8-119">Esse processo de servidor Web orientado ao serviço escuta solicitações que, depois, são entregues a outros processos em segundo plano que executam o código R real para gerar os resultados.</span><span class="sxs-lookup"><span data-stu-id="248a8-119">This service-oriented web server process listens for requests, which are then handed off to other background processes that run the actual R code to generate the results.</span></span> <span data-ttu-id="248a8-120">Todos esses processos são executados em um único nó nesta configuração, encapsulado em um contêiner.</span><span class="sxs-lookup"><span data-stu-id="248a8-120">All these processes run on a single node in this configuration, which is wrapped in a container.</span></span> <span data-ttu-id="248a8-121">Para obter detalhes sobre como usar esse serviço fora de um ambiente de desenvolvimento ou teste, entre em contato com seu representante da Microsoft.</span><span class="sxs-lookup"><span data-stu-id="248a8-121">For details about using this service outside a dev or test environment, contact your Microsoft representative.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="248a8-122">Considerações sobre o desempenho</span><span class="sxs-lookup"><span data-stu-id="248a8-122">Performance considerations</span></span>

<span data-ttu-id="248a8-123">Cargas de trabalho de aprendizado de máquina tendem a usar muitos recursos de computação, tanto durante o treinamento quanto ao pontuar novos dados.</span><span class="sxs-lookup"><span data-stu-id="248a8-123">Machine learning workloads tend to be compute-intensive, both when training and when scoring new data.</span></span> <span data-ttu-id="248a8-124">Como regra geral, tente não executar mais de um processo de pontuação por núcleo.</span><span class="sxs-lookup"><span data-stu-id="248a8-124">As a rule of thumb, try not to run more than one scoring process per core.</span></span> <span data-ttu-id="248a8-125">O Machine Learning Server permite definir o número de processos de R em execução em cada contêiner.</span><span class="sxs-lookup"><span data-stu-id="248a8-125">Machine Learning Server lets you define the number of R processes running in each container.</span></span> <span data-ttu-id="248a8-126">O padrão é de cinco processos.</span><span class="sxs-lookup"><span data-stu-id="248a8-126">The default is five processes.</span></span> <span data-ttu-id="248a8-127">Ao criar um modelo relativamente simples, como uma regressão linear com um pequeno número de variáveis, ou uma pequena árvore de decisões, você pode aumentar o número de processos.</span><span class="sxs-lookup"><span data-stu-id="248a8-127">When creating a relatively simple model, such as a linear regression with a small number of variables, or a small decision tree, you can increase the number of processes.</span></span> <span data-ttu-id="248a8-128">Monitore a carga da CPU em seus nós de cluster para determinar o limite apropriado do número de contêineres.</span><span class="sxs-lookup"><span data-stu-id="248a8-128">Monitor the CPU load on your cluster nodes to determine the appropriate limit on the number of containers.</span></span>

<span data-ttu-id="248a8-129">Um cluster habilitado para GPU pode acelerar alguns tipos de cargas de trabalho e, em particular, modelos de aprendizado avançado.</span><span class="sxs-lookup"><span data-stu-id="248a8-129">A GPU-enabled cluster can speed up some types of workloads, and deep learning models in particular.</span></span> <span data-ttu-id="248a8-130">Nem todas as cargas de trabalho podem aproveitar as GPUs &mdash;, somente aquelas que usam muita álgebra de matriz.</span><span class="sxs-lookup"><span data-stu-id="248a8-130">Not all workloads can take advantage of GPUs &mdash; only those that make heavy use of matrix algebra.</span></span> <span data-ttu-id="248a8-131">Por exemplo, modelos baseados em árvore, incluindo florestas aleatórias e modelos de reforço, geralmente não obtêm vantagens com GPUs.</span><span class="sxs-lookup"><span data-stu-id="248a8-131">For example, tree-based models, including random forests and boosting models, generally derive no advantage from GPUs.</span></span>

<span data-ttu-id="248a8-132">Alguns tipos de modelo, como as florestas aleatórias, são altamente paralelizáveis em CPUs.</span><span class="sxs-lookup"><span data-stu-id="248a8-132">Some model types such as random forests are massively parallelizable on CPUs.</span></span> <span data-ttu-id="248a8-133">Nesses casos, acelere a pontuação de uma única solicitação distribuindo a carga de trabalho entre vários núcleos.</span><span class="sxs-lookup"><span data-stu-id="248a8-133">In these cases, speed up the scoring of a single request by distributing the workload across multiple cores.</span></span> <span data-ttu-id="248a8-134">No entanto, isso reduz sua capacidade para lidar com várias solicitações de pontuação, devido a um tamanho fixo de cluster.</span><span class="sxs-lookup"><span data-stu-id="248a8-134">However, doing so reduces your capacity to handle multiple scoring requests given a fixed cluster size.</span></span>

<span data-ttu-id="248a8-135">Em geral, os modelos de R de software livre armazenam todos os seus dados na memória. Portanto, certifique-se de que seus nós tenham memória suficiente para acomodar os processos que você planeja executar simultaneamente.</span><span class="sxs-lookup"><span data-stu-id="248a8-135">In general, open-source R models store all their data in memory, so ensure that your nodes have enough memory to accommodate the processes you plan to run concurrently.</span></span> <span data-ttu-id="248a8-136">Se você estiver usando o Machine Learning Server para ajustar seus modelos, use as bibliotecas que podem processar dados em disco, em vez de lê-los na memória.</span><span class="sxs-lookup"><span data-stu-id="248a8-136">If you are using Machine Learning Server to fit your models, use the libraries that can process data on disk, rather than reading it all into memory.</span></span> <span data-ttu-id="248a8-137">Isso pode ajudar a reduzir consideravelmente os requisitos da memória.</span><span class="sxs-lookup"><span data-stu-id="248a8-137">This can help reduce memory requirements significantly.</span></span> <span data-ttu-id="248a8-138">Independentemente de você usar o Machine Learning Server ou o R de software livre, monitore seus nós para garantir que seus processos de pontuação não são fiquem sem memória.</span><span class="sxs-lookup"><span data-stu-id="248a8-138">Regardless of whether you use Machine Learning Server or open-source R, monitor your nodes to ensure that your scoring processes are not memory-starved.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="248a8-139">Considerações de segurança</span><span class="sxs-lookup"><span data-stu-id="248a8-139">Security considerations</span></span>

### <a name="network-encryption"></a><span data-ttu-id="248a8-140">Criptografia de rede</span><span class="sxs-lookup"><span data-stu-id="248a8-140">Network encryption</span></span>

<span data-ttu-id="248a8-141">Nessa arquitetura de referência, o HTTPS será habilitado para a comunicação com o cluster, e um certificado de preparo de [Let’s Encrypt][encrypt] será usado.</span><span class="sxs-lookup"><span data-stu-id="248a8-141">In this reference architecture, HTTPS is enabled for communication with the cluster, and a staging certificate from [Let’s Encrypt][encrypt] is used.</span></span> <span data-ttu-id="248a8-142">Para fins de produção, substitua seu próprio certificado por uma autoridade de assinatura apropriada.</span><span class="sxs-lookup"><span data-stu-id="248a8-142">For production purposes, substitute your own certificate from an appropriate signing authority.</span></span>

### <a name="authentication-and-authorization"></a><span data-ttu-id="248a8-143">Autenticação e autorização</span><span class="sxs-lookup"><span data-stu-id="248a8-143">Authentication and authorization</span></span>

<span data-ttu-id="248a8-144">A [Operacionalização de Modelo][operationalization] do Machine Learning Server exige a autenticação das solicitações de pontuação.</span><span class="sxs-lookup"><span data-stu-id="248a8-144">Machine Learning Server [Model Operationalization][operationalization] requires scoring requests to be authenticated.</span></span> <span data-ttu-id="248a8-145">Nessa implantação, usamos um nome de usuário e senha.</span><span class="sxs-lookup"><span data-stu-id="248a8-145">In this deployment, a username and password are used.</span></span> <span data-ttu-id="248a8-146">Em uma configuração empresarial, você pode habilitar a autenticação usando o [Azure Active Directory][AAD] ou criar um front-end separado usando o [Gerenciamento de API do Azure][API].</span><span class="sxs-lookup"><span data-stu-id="248a8-146">In an enterprise setting, you can enable authentication using [Azure Active Directory][AAD] or create a separate front end using [Azure API Management][API].</span></span>

<span data-ttu-id="248a8-147">Para que a Operacionalização de Modelo funcione corretamente com o Machine Learning Server em contêineres, você deve instalar um certificado JSON Web Token (JWT).</span><span class="sxs-lookup"><span data-stu-id="248a8-147">For Model Operationalization to work correctly with Machine Learning Server on containers, you must install a JSON Web Token (JWT) certificate.</span></span> <span data-ttu-id="248a8-148">Essa implantação usa um certificado fornecido pela Microsoft.</span><span class="sxs-lookup"><span data-stu-id="248a8-148">This deployment uses a certificate supplied by Microsoft.</span></span> <span data-ttu-id="248a8-149">Em um ambiente de produção, forneça o seu próprio.</span><span class="sxs-lookup"><span data-stu-id="248a8-149">In a production setting, supply your own.</span></span>

<span data-ttu-id="248a8-150">Para o tráfego entre o AKS e o Registro de Contêiner, considere habilitar o [controle de acesso baseado em função][rbac] (RBAC) para limitar os privilégios de acesso apenas para quem precisa.</span><span class="sxs-lookup"><span data-stu-id="248a8-150">For traffic between Container Registry and AKS, consider enabling [role-based access control][rbac] (RBAC) to limit access privileges to only those needed.</span></span>

### <a name="separate-storage"></a><span data-ttu-id="248a8-151">Armazenamento separado</span><span class="sxs-lookup"><span data-stu-id="248a8-151">Separate storage</span></span>

<span data-ttu-id="248a8-152">Essa arquitetura de referência agrupa o aplicativo (R) e os dados (objeto de modelo e script de pontuação) em uma única imagem.</span><span class="sxs-lookup"><span data-stu-id="248a8-152">This reference architecture bundles the application (R) and the data (model object and scoring script) into a single image.</span></span> <span data-ttu-id="248a8-153">Em alguns casos, talvez seja melhor separá-los.</span><span class="sxs-lookup"><span data-stu-id="248a8-153">In some cases, it may be beneficial to separate these.</span></span> <span data-ttu-id="248a8-154">Você pode colocar os dados e o código do modelo no [armazenamento][storage] de blobs ou arquivo do Azure, e recuperá-los na inicialização do contêiner.</span><span class="sxs-lookup"><span data-stu-id="248a8-154">You can place the model data and code into Azure blob or file [storage][storage], and retrieve them at container initialization.</span></span> <span data-ttu-id="248a8-155">Nesse caso, verifique se a conta de armazenamento está definida para permitir apenas o acesso autenticado e exigir HTTPS.</span><span class="sxs-lookup"><span data-stu-id="248a8-155">In this case, ensure that the storage account is set to allow authenticated access only and require HTTPS.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="248a8-156">Considerações de monitoramento e registro em log</span><span class="sxs-lookup"><span data-stu-id="248a8-156">Monitoring and logging considerations</span></span>

<span data-ttu-id="248a8-157">Use o [painel do Kubernetes][dashboard] para monitorar o status geral do cluster do AKS.</span><span class="sxs-lookup"><span data-stu-id="248a8-157">Use the [Kubernetes dashboard][dashboard] to monitor the overall status of your AKS cluster.</span></span> <span data-ttu-id="248a8-158">Consulte a folha de visão geral do cluster no portal do Azure para obter mais detalhes.</span><span class="sxs-lookup"><span data-stu-id="248a8-158">See the cluster’s overview blade in Azure portal for more details.</span></span> <span data-ttu-id="248a8-159">Os recursos do [GitHub][github] também mostram como exibir o painel de R.</span><span class="sxs-lookup"><span data-stu-id="248a8-159">The [GitHub][github] resources also show how to bring up the dashboard from R.</span></span>

<span data-ttu-id="248a8-160">Embora o painel forneça uma exibição da integridade geral do seu cluster, também é importante acompanhar o status dos contêineres individuais.</span><span class="sxs-lookup"><span data-stu-id="248a8-160">Although the dashboard gives you a view of the overall health of your cluster, it’s also important to track the status of individual containers.</span></span> <span data-ttu-id="248a8-161">Para fazer isso, habilite o [Insights do Azure Monitor][monitor] na folha de visão geral do cluster no portal do Azure, ou confira [Azure Monitor para contêineres][monitor-containers] (em versão prévia).</span><span class="sxs-lookup"><span data-stu-id="248a8-161">To do this, enable [Azure Monitor Insights][monitor] from the cluster overview blade in Azure portal, or see [Azure Monitor for containers][monitor-containers] (in preview).</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="248a8-162">Considerações de custo</span><span class="sxs-lookup"><span data-stu-id="248a8-162">Cost considerations</span></span>

<span data-ttu-id="248a8-163">O Machine Learning Server é licenciado por núcleo, e todos os núcleos no cluster que executarão o Machine Learning Server contam para isso.</span><span class="sxs-lookup"><span data-stu-id="248a8-163">Machine Learning Server is licensed on a per-core basis, and all the cores in the cluster that will run Machine Learning  Server count towards this.</span></span> <span data-ttu-id="248a8-164">Se você for um cliente empresarial do Machine Learning Server ou do Microsoft SQL Server, entre em contato com seu representante da Microsoft para obter detalhes sobre preços.</span><span class="sxs-lookup"><span data-stu-id="248a8-164">If you are an enterprise Machine Learning Server or Microsoft SQL Server customer, contact your Microsoft representative for pricing details.</span></span>

<span data-ttu-id="248a8-165">Uma alternativa de software livre ao Machine Learning Server é [Plumber][plumber], um pacote R que transforma seu código em uma API REST.</span><span class="sxs-lookup"><span data-stu-id="248a8-165">An open-source alternative to Machine Learning Server is [Plumber][plumber], an R package that turns your code into a REST API.</span></span> <span data-ttu-id="248a8-166">O Plumber tem menos recursos do que o Machine Learning Server.</span><span class="sxs-lookup"><span data-stu-id="248a8-166">Plumber is less fully featured than Machine Learning Server.</span></span> <span data-ttu-id="248a8-167">Por exemplo, por padrão, ele não inclui todos os recursos que fornecem autenticação da solicitação.</span><span class="sxs-lookup"><span data-stu-id="248a8-167">For example, by default it doesn't include any features that provide request authentication.</span></span> <span data-ttu-id="248a8-168">Se você usar Plumber, recomendamos que você habilite o [Gerenciamento de API do Azure][API] para lidar com detalhes de autenticação.</span><span class="sxs-lookup"><span data-stu-id="248a8-168">If you use Plumber, it’s recommended that you enable [Azure API Management][API] to handle authentication details.</span></span>

<span data-ttu-id="248a8-169">Além do licenciamento, a principal consideração de custo são os recursos de computação do cluster Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="248a8-169">Besides licensing, the main cost consideration is the Kubernetes cluster's compute resources.</span></span> <span data-ttu-id="248a8-170">O cluster deve ser grande o suficiente para lidar com o volume de solicitação esperado em horários de pico, mas essa abordagem deixa recursos ociosos em outros momentos.</span><span class="sxs-lookup"><span data-stu-id="248a8-170">The cluster must be large enough to handle the expected request volume at peak times, but this approach leaves resources idle at other times.</span></span> <span data-ttu-id="248a8-171">Para limitar o impacto dos recursos ociosos, habilite o [dimensionador automático horizontal][autoscaler] para o cluster usando a ferramenta kubectl.</span><span class="sxs-lookup"><span data-stu-id="248a8-171">To limit the impact of idle resources, enable the [horizontal autoscaler][autoscaler] for the cluster using the kubectl tool.</span></span> <span data-ttu-id="248a8-172">Ou, use o [dimensionador automático de cluster][cluster-autoscaler] do AKS.</span><span class="sxs-lookup"><span data-stu-id="248a8-172">Or use the AKS [cluster autoscaler][cluster-autoscaler].</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="248a8-173">Implantar a solução</span><span class="sxs-lookup"><span data-stu-id="248a8-173">Deploy the solution</span></span>

<span data-ttu-id="248a8-174">Há uma implantação de referência para essa arquitetura disponível no [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="248a8-174">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="248a8-175">Execute as etapas descritas para implantar um modelo de previsão simples como um serviço.</span><span class="sxs-lookup"><span data-stu-id="248a8-175">Follow the steps described there to deploy a simple predictive model as a service.</span></span>

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
